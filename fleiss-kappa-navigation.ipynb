{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fleiss' Kappa Explorer\n",
    "Measuring interrater agreement for each rater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First round of agreement measures\n",
    "We did this round to see if the labels we settled on were practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"fleisspilot1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = data[[\"rater_1\", \"rater_2\"]]\n",
    "conversions = dict([(\"News\", 0), (\"Politicians\", 1), (\"Activists\", 2), (\"Black Twitter\", 3), (\"Celebrities\", 4), (\"Organizations\", 5),\n",
    "(\"Professional\", 6),  (\"Professional\", 6), (\"Other\", 7), (\"NaN\", 8)])\n",
    "conversions\n",
    "\n",
    "for i in transform.columns:\n",
    "    transform[i] = transform[i].map(conversions)  #map cats to nums\n",
    "\n",
    "dats, cats= irr.aggregate_raters(transform, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fleiss2 = pd.read_csv(\"fleisspilot2.csv\")\n",
    "transform2 = fleiss2[[\"rater_1\", \"rater_2\"]] #get only the ratings\n",
    "\n",
    "for i in transform2.columns:\n",
    "    transform2[i] = transform2[i].map(conversions)\n",
    "\n",
    "dats2, cats2 = irr.aggregate_raters(transform2, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats2, method='fleiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8314840499306517"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.8571428571428571, 0.8058252427184465])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second round of agreement measures\n",
    "We did this round when labeling all 65 communities, to double check that our annotations could be trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fleiss Maximizer Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno1 = []\n",
    "anno2 = []\n",
    "def get_highest_fleiss():\n",
    "    for i in range(0,19):\n",
    "        if data.loc[:, \"rater_11\"][i] == data.loc[:, \"rater_21\"][i]:\n",
    "            anno1.append(data.loc[:, \"rater_11\"][i])\n",
    "            anno2.append(data.loc[:, \"rater_21\"][i])\n",
    "        elif data.loc[:, \"rater_11\"][i] == data.loc[:, \"rater_22\"][i]:\n",
    "            anno1.append(data.loc[:, \"rater_11\"][i])\n",
    "            anno2.append(data.loc[:, \"rater_22\"][i])   \n",
    "        elif data.loc[:, \"rater_12\"][i] == data.loc[:, \"rater_21\"][i]:\n",
    "            anno1.append(data.loc[:, \"rater_12\"][i])\n",
    "            anno2.append(data.loc[:, \"rater_21\"][i]) \n",
    "        else: #none equal OR this one happens to be equal. in either case, doesnt matter, use data.loc[:, \"rater_12\"][i], data.loc[:, \"rater_22\"][i]\n",
    "            anno1.append(data.loc[:, \"rater_12\"][i])\n",
    "            anno2.append(data.loc[:, \"rater_22\"][i])\n",
    "\n",
    "    return pd.DataFrame(list(zip(anno1, anno2)), columns = [\"anno1\", \"anno2\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['T3_C52', 'T4_C40']** Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./new_fleiss1.csv\").fillna(\"None\") #doing confusion matrix through an error when NaNs were present\n",
    "\n",
    "#transform = data[[\"rater_11\", \"rater_12\", \"rater_21\", \"rater_22\"]]\n",
    "conversions = dict([(\"Established Media\", 0), (\"Politicians\", 1), (\"Activists\", 2), (\"Black Twitter\", 3), (\"Celebrities\", 4), (\"Organizations\", 5),\n",
    "(\"Professional (individual)\", 6),  (\"Professional\", 7), (\"Other\", 8), (\"None\", 9)])\n",
    "\n",
    "sub = data.loc[:, [\"rater_11\", \"rater_21\"]]\n",
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))\n",
    "\n",
    "sub = data.loc[:, [\"rater_11\", \"rater_22\"]]\n",
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = get_highest_fleiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp = ConfusionMatrixDisplay.from_predictions (sub.anno1, sub.anno2, labels=list(conversions.keys()), xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_xlabel (\"Ann3's annotations\")\n",
    "disp.ax_.set_ylabel (\"Ann4's annotations\")\n",
    "disp.ax_.set_title (\"Annotations of Highest Fleiss' Kappa for ['T3_C52', 'T4_C40']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Fleiss\n",
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['T0_C5', 'T1_C0', 'T2_C1', 'T3_C1', 'T4_C0', 'T5_C1']** Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./new_fleiss2.csv\").fillna(\"None\")  \n",
    "anno1 = []\n",
    "anno2 = []\n",
    "sub = get_highest_fleiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp = ConfusionMatrixDisplay.from_predictions (sub.anno1, sub.anno2, labels=list(conversions.keys()), xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_xlabel (\"Ann4's annotations\")\n",
    "disp.ax_.set_ylabel (\"Ann1's annotations\")\n",
    "disp.ax_.set_title (\"Annotations of Highest Fleiss' Kappa for ['T0_C5', 'T1_C0', 'T2_C1', 'T3_C1', 'T4_C0', 'T5_C1']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['T3_C13', 'T4_C8', 'T5_C9', 'T6_C9']** Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./new_fleiss3.csv\").fillna(\"None\")\n",
    "anno1 = []\n",
    "anno2 = []\n",
    "sub = get_highest_fleiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp = ConfusionMatrixDisplay.from_predictions (sub.anno1, sub.anno2, labels=list(conversions.keys()), xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_xlabel (\"Ann1's annotations\")\n",
    "disp.ax_.set_ylabel (\"Ann2's annotations\")\n",
    "disp.ax_.set_title (\"Annotations of Highest Fleiss' Kappa for ['T3_C13', 'T4_C8', 'T5_C9', 'T6_C9']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['T2_C34', 'T3_C63', 'T4_C43']** Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./new_fleiss4.csv\").fillna(\"None\")\n",
    "anno1 = []\n",
    "anno2 = []\n",
    "sub = get_highest_fleiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp = ConfusionMatrixDisplay.from_predictions (sub.anno1, sub.anno2, labels=list(conversions.keys()), xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_xlabel (\"Ann3's annotations\")\n",
    "disp.ax_.set_ylabel (\"Ann2's annotations\")\n",
    "disp.ax_.set_title (\"Annotations of Highest Fleiss' Kappa for ['T2_C34', 'T3_C63', 'T4_C43']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['T4_C9', 'T5_C4', 'T6_C8']** Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./new_fleiss5.csv\").fillna(\"None\")\n",
    "anno1 = []\n",
    "anno2 = []\n",
    "sub = get_highest_fleiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp = ConfusionMatrixDisplay.from_predictions (sub.anno1, sub.anno2, labels=list(conversions.keys()), xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_xlabel (\"Ann2's annotations\")\n",
    "disp.ax_.set_ylabel (\"Ann4's annotations\")\n",
    "disp.ax_.set_title (\"Annotations of Highest Fleiss' Kappa for ['T4_C9', 'T5_C4', 'T6_C8']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**['T0_C41', 'T1_C34']** Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./new_fleiss6.csv\").fillna(\"None\")\n",
    "anno1 = []\n",
    "anno2 = []\n",
    "sub = get_highest_fleiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "disp = ConfusionMatrixDisplay.from_predictions (sub.anno1, sub.anno2, labels=list(conversions.keys()), xticks_rotation=\"vertical\")\n",
    "disp.ax_.set_xlabel (\"Ann1's annotations\")\n",
    "disp.ax_.set_ylabel (\"Ann3's annotations\")\n",
    "disp.ax_.set_title (\"Annotations of Highest Fleiss' Kappa for ['T0_C41', 'T1_C34']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub.columns:\n",
    "    sub[i] = sub[i].map(conversions)\n",
    "dats, cats = irr.aggregate_raters(sub, n_cat=None)\n",
    "print(irr.fleiss_kappa(dats, method='fleiss'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean\n",
    "np.mean([0.6707105719237435, 0.845213849287169, 0.6122448979591837, 0.8716216216216217, 0.8535645472061657, 0.9339130434782608])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
